{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k-V9JzqnxeHD",
        "fL4v8Detxl5k"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1r_ElyehZwlWC7je1ZCsrauqKAObqnjNN?usp=sharing)\n",
        "\n",
        "# Violence Detection In Movie Scenes"
      ],
      "metadata": {
        "id": "OFgTD_PAXmUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the runtime"
      ],
      "metadata": {
        "id": "II784z1uYNdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-convert"
      ],
      "metadata": {
        "id": "YzX5K-pfW0DP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922aa590-1cdc-4506-9542-ef548c8447e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colab-convert\n",
            "  Downloading colab-convert-2.0.5.tar.gz (18 kB)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.10-py2.py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: colab-convert\n",
            "  Building wheel for colab-convert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-convert: filename=colab_convert-2.0.5-py3-none-any.whl size=19224 sha256=433c19571c3c447ddaa7553ec51fa7089200d7f02a94bc6b41e29406ebfdc659\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/f2/9d/ee946c8db91ba06736f0fc6d0391421f891d5e19785ce707f6\n",
            "Successfully built colab-convert\n",
            "Installing collected packages: json5, colab-convert\n",
            "Successfully installed colab-convert-2.0.5 json5-0.9.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show colab-convert\n",
        "print()\n",
        "!pip show numpy\n",
        "print()\n",
        "!pip show tensorflow\n",
        "print()\n",
        "!pip show opencv-python\n",
        "print()\n",
        "!pip show pyyaml\n",
        "print()\n",
        "!pip show h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HNxQirlYbcB",
        "outputId": "2d2f984f-d97b-4dd7-bf0d-12ab7342d676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: colab-convert\n",
            "Version: 2.0.5\n",
            "Summary: Convert .py files runnable in VSCode/Python or Atom/Hydrogen to jupyter/colab .ipynb notebooks and vice versa\n",
            "Home-page: https://github.com/MSFTserver/colab-convert\n",
            "Author: HostsServer\n",
            "Author-email: msftserver@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: json5\n",
            "Required-by: \n",
            "\n",
            "Name: numpy\n",
            "Version: 1.21.6\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: yellowbrick, xgboost, xarray, xarray-einstats, wordcloud, torchvision, torchtext, tifffile, thinc, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-datasets, tensorboard, tables, statsmodels, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, scikit-image, resampy, qudida, qdldl, PyWavelets, python-louvain, pystan, pysndfile, pymc, pyerfa, pyemd, pycocotools, pyarrow, prophet, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-python-headless, opencv-contrib-python, numexpr, numba, nibabel, netCDF4, moviepy, mlxtend, mizani, missingno, matplotlib, matplotlib-venn, lightgbm, librosa, Keras-Preprocessing, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, httpstan, holoviews, h5py, gym, gensim, folium, fix-yahoo-finance, fastdtw, fa2, ecos, datascience, daft, cvxpy, cupy-cuda111, cufflinks, cmdstanpy, cftime, bokeh, blis, autograd, atari-py, astropy, arviz, altair, albumentations, aesara, aeppl\n",
            "\n",
            "Name: tensorflow\n",
            "Version: 2.8.2+zzzcolab20220719082949\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: gast, google-pasta, libclang, tensorflow-io-gcs-filesystem, typing-extensions, six, h5py, wrapt, keras, numpy, flatbuffers, grpcio, termcolor, setuptools, astunparse, protobuf, opt-einsum, tensorflow-estimator, keras-preprocessing, absl-py, tensorboard\n",
            "Required-by: kapre\n",
            "\n",
            "Name: opencv-python\n",
            "Version: 4.6.0.66\n",
            "Summary: Wrapper package for OpenCV python bindings.\n",
            "Home-page: https://github.com/skvark/opencv-python\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: imgaug, dopamine-rl\n",
            "\n",
            "Name: PyYAML\n",
            "Version: 6.0\n",
            "Summary: YAML parser and emitter for Python\n",
            "Home-page: https://pyyaml.org/\n",
            "Author: Kirill Simonov\n",
            "Author-email: xi@resolvent.net\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: PyDrive, fastai, distributed, dask, bokeh, albumentations\n",
            "\n",
            "Name: h5py\n",
            "Version: 3.1.0\n",
            "Summary: Read and write HDF5 files from Python\n",
            "Home-page: http://www.h5py.org\n",
            "Author: Andrew Collette\n",
            "Author-email: andrew.collette@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: cached-property, numpy\n",
            "Required-by: tensorflow, keras-vis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive"
      ],
      "metadata": {
        "id": "wryP8k9KXdPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y09Bw_IGCtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b40a0c-c6cc-4e0c-ed11-c7b96113ba7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/automatic-detection-of-violence-in-video-scenes\n",
            "cc-outputs.log  convert.txt  .gitignore          info.txt     requirements.txt\n",
            "\u001b[0m\u001b[01;34mCombined\u001b[0m/       \u001b[01;36mCrowd2\u001b[0m@      git_interactive.py  \u001b[01;34mMovies\u001b[0m/      sync.sh\n",
            "config_user.sh  \u001b[01;34m.git\u001b[0m/        \u001b[01;36mHockey\u001b[0m@             new_repo.sh\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cd '/content/drive/MyDrive/automatic-detection-of-violence-in-video-scenes'\n",
        "%ls -a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "s2so4O8CYpEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow      import keras\n",
        "from keras           import layers as tfl\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.backend   import clear_session\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "tf.test.gpu_device_name()\n",
        "# Standard output is '/device:GPU:0'"
      ],
      "metadata": {
        "id": "lt1G6WwGYv-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1454d2f-c8d8-42ac-c85e-7bed7771e541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sync with Github"
      ],
      "metadata": {
        "id": "GSzKcCYSXh0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config user.email \"moharamfatema@gmail.com\"\n",
        "# !git config user.name \"moharamfatema\"\n",
        "\n",
        "# !python3 git_interactive.py"
      ],
      "metadata": {
        "id": "qshzMq_JVbcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e77d9d8-c37f-4528-9e33-067b0e70616c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repo owner: moharamfatema\n",
            "repo name: violence-detection-paper-replicatio\n",
            "Enter your username:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git add Movies/movies-data.py\n",
        "# !git commit -m \"+svm and rf movies\"\n",
        "# !git push moharamfatema-origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnRKMI5iuNaZ",
        "outputId": "9ea01cc7-8539-47c6-9927-4d3178438edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cc-outputs.log  \u001b[0m\u001b[01;36mCrowd2\u001b[0m@           git_interactive.py  new_repo.sh\n",
            "\u001b[01;34mCombined\u001b[0m/       forest_model.pkl  \u001b[01;36mHockey\u001b[0m@             requirements.txt\n",
            "config_user.sh  \u001b[01;34m.git\u001b[0m/             info.txt            svm_model.pkl\n",
            "convert.txt     .gitignore        \u001b[01;34mMovies\u001b[0m/             sync.sh\n",
            "[main 767af37] +svm and rf movies\n",
            " 1 file changed, 439 insertions(+), 118 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "YhHJ07ZWZCzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Constants"
      ],
      "metadata": {
        "id": "k-V9JzqnxeHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input paths\n",
        "\n",
        "ROOT_PATH = '/content/drive/MyDrive/automatic-detection-of-violence-in-video-scenes'\n",
        "MOVIES_PATH = ROOT_PATH + '/Movies/Movies Fight Dataset'\n",
        "\n",
        "VIOLENCE_PATH = MOVIES_PATH + '/Violence'\n",
        "NORMAL_PATH = MOVIES_PATH + '/Normal'\n",
        "\n",
        "print(os.listdir(NORMAL_PATH)[-1])\n",
        "print(os.listdir(VIOLENCE_PATH)[-1])\n",
        "\n",
        "# define output paths\n",
        "\n",
        "OUT_PATH = ROOT_PATH + '/Movies/out'\n"
      ],
      "metadata": {
        "id": "tKkvBlmCZF-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188eb65b-6888-46a1-82e6-324230dedad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60.mpg\n",
            "newfi67.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process raw data"
      ],
      "metadata": {
        "id": "fL4v8Detxl5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title define extraction function\n",
        "# @markdown define the default parameters:\n",
        "\n",
        "DIMENSIONS = (50, 50) # @param\n",
        "PACKET_LENGTH = 15 # @param\n",
        "\n",
        "def extract_frames(\n",
        "    directory: str, \n",
        "    permutation: np.ndarray,\n",
        "    dimensions: tuple = DIMENSIONS, \n",
        "    packet_length: int = PACKET_LENGTH, \n",
        "    save_path: str = None\n",
        "    ) -> np.ndarray:\n",
        "  \"\"\" Extract packets from video directory\n",
        "\n",
        "  Parameters\n",
        "  -----------\n",
        "  directory : str\n",
        "    A directory on the disk that contains the videos \n",
        "\n",
        "  dimensions: Tuple of shape 2 , optional\n",
        "    The desired frame dimensions to be stored\n",
        "    default = (50,50)\n",
        "\n",
        "  permutation : tuple\n",
        "    the boundaries of the data taken from the directory\n",
        "\n",
        "  packet_length: int , optional\n",
        "    Packet length , Default = 15\n",
        "\n",
        "  save_dir : str , optional\n",
        "    The path to which the axtracted data should be saved\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ndarray \n",
        "    The extracted packets from each video stacked together \n",
        "  \"\"\"\n",
        "  data = []\n",
        "    \n",
        "  for video_name in np.array(os.listdir(directory))[permutation]:\n",
        "    video = cv2.VideoCapture(directory + '/' + video_name )\n",
        "    packet = []\n",
        "    i = 0\n",
        "\n",
        "    while video.isOpened():\n",
        "      ret, frame = video.read()\n",
        "\n",
        "      if not ret: # no more frames\n",
        "        break\n",
        "      \n",
        "      del ret\n",
        "\n",
        "      if i % 2 == 0: # capture one in every 2 frames\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "      # capturing the frame\n",
        "\n",
        "      frame = cv2.resize(frame, dimensions, interpolation = cv2.INTER_AREA)\n",
        "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "      packet.append(frame)\n",
        "      del frame\n",
        "\n",
        "      if len(packet) == packet_length: \n",
        "        '''\n",
        "        consecutive packets share 14 of the 15 frames to generate more data\n",
        "        '''\n",
        "        # packet itself is not normalized\n",
        "        stacked = np.array(packet) / 255. # convert to numpy and normalize packet\n",
        "        data.append(stacked.copy()) # this .copy() is not in the original code \n",
        "        packet.pop(0) \n",
        "\n",
        "      i += 1\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "  \n",
        "  del packet\n",
        "  # TODO: read the docs for the next 2 lines\n",
        "  data = np.stack(data, axis= 0)\n",
        "  data = np.moveaxis(data, 1 ,-1)\n",
        "\n",
        "  # save to disk\n",
        "  if(save_path is not None):\n",
        "    np.save(f'{save_path}',data)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "cellView": "code",
        "id": "erY_qjG0b_QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_np(normal, violence):\n",
        "  subset = min(len(normal),len(violence))\n",
        "\n",
        "  y = np.concatenate([np.zeros(subset), np.ones(subset)])\n",
        "  x = np.concatenate([normal[:subset,:,:,:], violence[:subset,:,:,:]], axis = 0)\n",
        "\n",
        "  print((x.shape, y.shape))\n",
        "\n",
        "  #shuffle\n",
        "  per = np.random.permutation(len(x))\n",
        "\n",
        "  x = x[per,:,:,:]\n",
        "  y = y[per]\n",
        "  y = y.astype(int)\n",
        "\n",
        "  y = np.expand_dims(y, -1)\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "8fR5dkaIolrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_datasets(\n",
        "    save_path: str\n",
        "  ) -> np.ndarray:\n",
        "  \n",
        "  normal_random = np.random.permutation(100)\n",
        "  violence_random = np.random.permutation(100)\n",
        "\n",
        "  # train\n",
        "  normal_data = extract_frames(f'{MOVIES_PATH}/Normal', normal_random[:70])\n",
        "  violence_data = extract_frames(f'{MOVIES_PATH}/Violence', violence_random[:70])\n",
        "\n",
        "  x, y = process_np(normal_data, violence_data)\n",
        "  del normal_data\n",
        "  del violence_data\n",
        "\n",
        "  np.save(f'{save_path}/x_train',x)\n",
        "  np.save(f'{save_path}/y_train',y)\n",
        "\n",
        "  del x\n",
        "  del y\n",
        "\n",
        "  # validation\n",
        "  normal_data = extract_frames(f'{MOVIES_PATH}/Normal', normal_random[70:85])\n",
        "  violence_data = extract_frames(f'{MOVIES_PATH}/Violence', violence_random[70:85])\n",
        "\n",
        "  x, y = process_np(normal_data, violence_data)\n",
        "  del normal_data\n",
        "  del violence_data\n",
        "\n",
        "  np.save(f'{save_path}/x_val',x)\n",
        "  np.save(f'{save_path}/y_val',y)\n",
        "\n",
        "  del x\n",
        "  del y\n",
        "\n",
        "  # test\n",
        "  normal_data = extract_frames(f'{MOVIES_PATH}/Normal', normal_random[85:])\n",
        "  violence_data = extract_frames(f'{MOVIES_PATH}/Violence', violence_random[85:])\n",
        "\n",
        "  x, y = process_np(normal_data, violence_data)\n",
        "  del normal_data\n",
        "  del violence_data\n",
        "\n",
        "  np.save(f'{save_path}/x_test',x)\n",
        "  np.save(f'{save_path}/y_test',y)\n",
        "\n",
        "  del x\n",
        "  del y"
      ],
      "metadata": {
        "id": "VbXIN_GBkWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_datasets(OUT_PATH)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "qGt3_SkxiEIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pre-saved and pre-processed data"
      ],
      "metadata": {
        "id": "eGjHzNzpxrn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "\n",
        "def load_x_y(\n",
        "    load_which: str = 'train', \n",
        "  ):\n",
        "  violence_data = None\n",
        "  normal_data = None\n",
        "\n",
        "  if load_which == 'train':\n",
        "    x = np.load(f'{OUT_PATH}/x_train.npy')\n",
        "    y  = np.load(f'{OUT_PATH}/y_train.npy')\n",
        "\n",
        "  elif load_which == 'validation':\n",
        "    x = np.load(f'{OUT_PATH}/x_val.npy')\n",
        "    y  = np.load(f'{OUT_PATH}/y_val.npy')\n",
        "\n",
        "  elif load_which == 'test':\n",
        "    x = np.load(f'{OUT_PATH}/x_test.npy')\n",
        "    y  = np.load(f'{OUT_PATH}/y_test.npy')\n",
        "\n",
        "  print(f'y shape = {y.shape}')\n",
        "  print(f'x shape = {x.shape}')\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "cellView": "code",
        "id": "8tUXDs8iuVu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = load_x_y('train')\n",
        "\n",
        "x_val, y_val = load_x_y('validation')\n",
        "\n",
        "x_test, y_test = load_x_y('test')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU-4d1OPvTJd",
        "outputId": "35a2146c-ee57-4dc0-949a-2464dad8befb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape = (1414, 1)\n",
            "x shape = (1414, 50, 50, 15)\n",
            "y shape = (284, 1)\n",
            "x shape = (284, 50, 50, 15)\n",
            "y shape = (288, 1)\n",
            "x shape = (288, 50, 50, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Description"
      ],
      "metadata": {
        "id": "cWOBvYxchjif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# del model"
      ],
      "metadata": {
        "id": "U4S-W3JZie7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = keras.Sequential([\n",
        "    tfl.Conv2D(\n",
        "        128, \n",
        "        (3,3), \n",
        "        activation = 'relu',\n",
        "        input_shape = (50, 50, 15),\n",
        "        padding = 'same'\n",
        "      ),\n",
        "    tfl.Dropout(0.2),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.BatchNormalization(),\n",
        "\n",
        "    tfl.Conv2D(256, (3,3), activation = 'relu'),\n",
        "    tfl.Conv2D(256, (3,3), activation = 'relu', padding = 'same'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.BatchNormalization(),\n",
        "\n",
        "    tfl.Conv2D(512, (3,3), activation = 'relu'),\n",
        "    tfl.Conv2D(512, (3,3), activation = 'relu', padding = 'same'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.BatchNormalization(),\n",
        "\n",
        "    tfl.Conv2D(1024, (3,3), activation = 'relu', padding = 'same'),\n",
        "    tfl.Conv2D(1024, (3,3), activation = 'relu', padding = 'same'),\n",
        "    tfl.MaxPooling2D(2,2),\n",
        "    tfl.BatchNormalization(),\n",
        "\n",
        "    # Flatten the results to feed into the densely connected laye.\n",
        "    tfl.Flatten(),\n",
        "    # 512 neuron hidden laye.\n",
        "    tfl.Dense(2048, activation = 'relu'),\n",
        "    tfl.Dropout(0.2),\n",
        "\n",
        "    tfl.Dense(512, activation = 'relu'),\n",
        "    tfl.Dropout(0.2),\n",
        "\n",
        "    tfl.Dense(128, activation = 'relu'),\n",
        "    tfl.Dropout(0.2),\n",
        "\n",
        "    # Only 1 output neuron for binary classification tas.\n",
        "    tfl.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss = 'binary_crossentropy',\n",
        "      optimizer = keras.optimizers.Adam(learning_rate = 0.00003),\n",
        "      metrics = ['acc', keras.metrics.Recall(), keras.metrics.Precision()]\n",
        "    )\n",
        "  \n",
        "  return model\n",
        "\n",
        "# model = create_model()\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "1kH-GVkfhp38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "# !rm -rf ./logs/ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKjzSYEujKQO",
        "outputId": "8a51453f-c09b-4569-95f8-84043697a337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = EarlyStopping(patience = 13, restore_best_weights= True)\n",
        "\n",
        "log_dir = OUT_PATH + \"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
      ],
      "metadata": {
        "id": "pM3_CWQErao-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "history = model.fit(x = x_train,\n",
        "          y = y_train,\n",
        "          batch_size = 20,\n",
        "          epochs=100,\n",
        "          validation_data = (x_val, y_val),          \n",
        "          callbacks=early_stopping_cb,\n",
        "  )\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8sL52emixS_",
        "outputId": "b7af91d5-7f34-4d5f-a169-2e43d5619157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "71/71 [==============================] - 22s 92ms/step - loss: 0.1150 - acc: 0.9569 - recall: 0.9802 - precision: 0.9365 - val_loss: 0.6506 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 4s 56ms/step - loss: 0.0049 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3048 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 4s 56ms/step - loss: 0.0021 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.2492 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 4s 56ms/step - loss: 8.5153e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.2275 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 4s 56ms/step - loss: 7.6213e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.5466 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 4s 57ms/step - loss: 5.5091e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.8791 - val_acc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 4s 57ms/step - loss: 2.6679e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4729 - val_acc: 0.5563 - val_recall: 1.0000 - val_precision: 0.5299\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 2.2405e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.3128 - val_acc: 0.8134 - val_recall: 1.0000 - val_precision: 0.7282\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 1.8531e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0456 - val_acc: 0.9824 - val_recall: 1.0000 - val_precision: 0.9660\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 1.0851e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 4s 61ms/step - loss: 1.0795e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 1.3941e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 6.6831e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 4s 61ms/step - loss: 5.4120e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 4.5500e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 4.0870e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 5.1936e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 18/100\n",
            "71/71 [==============================] - 4s 63ms/step - loss: 4.0925e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 19/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 4.1744e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 20/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 2.8981e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 2.9304e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 22/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 3.7125e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.6464e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 23/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 2.3585e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.6370e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 24/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 1.7146e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 3.2206e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 25/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 5.0179e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 26/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 2.2290e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 7.5177e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 27/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 2.5470e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.9909e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 28/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 1.1445e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 5.3823e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 29/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 1.8734e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.4142e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 30/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 7.3052e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 4.1715e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 31/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 1.3570e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 32/100\n",
            "71/71 [==============================] - 4s 60ms/step - loss: 7.4356e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 33/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 5.2282e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 34/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 2.5764e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 9.8783e-04 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 35/100\n",
            "71/71 [==============================] - 4s 58ms/step - loss: 2.2716e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n",
            "Epoch 36/100\n",
            "71/71 [==============================] - 4s 59ms/step - loss: 1.2857e-05 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.load_weights(f'{OUT_PATH}/checkpoints/model-30-8-22-23-23')"
      ],
      "metadata": {
        "id": "_8K8VLrIoCqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb726af-9fcd-4748-e96b-81981fb123fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2a63606910>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_history = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o_-10qvjrAM",
        "outputId": "71a11bdb-6ccb-477b-81a1-dd44da1ef4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 12s 19ms/step - loss: 3.3979e-04 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "kgeu_VGxqFKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "Z6X89WBuqHwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing ROC curve\n"
      ],
      "metadata": {
        "id": "Ymp8cMYSruTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# roc curve for logistic regression model with optimal threshold\n",
        "from numpy import sqrt\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "# keep probabilities for the positive outcome only\n",
        "y_pred = y_pred[:]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(y_test, y_pred)\n",
        "lr_auc = roc_auc_score(y_test, y_pred)\n",
        "# summarize scores\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "# calculate the g-mean for each threshold\n",
        "gmeans = sqrt(tpr * (1-fpr))\n",
        "# locate the index of the largest g-mean\n",
        "ix = argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "w5j3wcd7ryzg",
        "outputId": "71fadf88-8da5-4ac2-c02a-ba24250c6bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic: ROC AUC=1.000\n",
            "Best Threshold=0.970337, G-Mean=1.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(y_test, y_pred, pos_label=1)\n",
        "fnr = 1 - tpr\n",
        "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "print('EER: %f' % EER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWyPfvqGr2-x",
        "outputId": "c03ce36d-3772-4d33-c573-28a958b3f02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EER: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "nTTndv0Zsipe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = [1 * (x[0]>=thresholds[ix]) for x in y_pred]\n",
        "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_pred).numpy()"
      ],
      "metadata": {
        "id": "MuFNV-gPskrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=3)\n",
        " \n",
        "con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "                     index = [0,1], \n",
        "                     columns = [0,1])"
      ],
      "metadata": {
        "id": "2dQAosDXsiKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')  \n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5oE2u2rpsoYL",
        "outputId": "bff05d0a-2401-4b76-be7d-cbab051a1c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = (con_mat[0][0] + con_mat[1][1]) / (con_mat[0][0] + con_mat[0][1] + con_mat[1][0] + con_mat[1][1]) \n",
        "print('Accuracy when predicting based on best threshold: %f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDnd1PlAsuF7",
        "outputId": "8058ff5a-7d61-49b2-c930-52caa17f5273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy when predicting based on best threshold: 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features from dense layer and use it to train an SVM classifier and a RF classifier"
      ],
      "metadata": {
        "id": "aKckwu9fs1As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_feat = keras.models.Model(inputs=model.input,outputs=model.layers[-7].output)"
      ],
      "metadata": {
        "id": "Z71Bh1BBs18V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_train = model_feat.predict(x_train)\n",
        "print(feat_train.shape)\n",
        "\n",
        "feat_val = model_feat.predict(x_val)\n",
        "print(feat_val.shape)\n",
        "\n",
        "feat_test = model_feat.predict(x_test)\n",
        "print(feat_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TWr7Lw9s5GR",
        "outputId": "b6b0568a-37b7-4dd6-fa2b-eee9ef1776b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1414, 2048)\n",
            "(284, 2048)\n",
            "(288, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "svm.fit(feat_train,y_train)\n",
        "\n",
        "print('fitting done !!!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXP1nBDytPaO",
        "outputId": "23affe7f-964d-4764-ed1c-599740f435d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting done !!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm.score(feat_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuGN84CftReH",
        "outputId": "afcd2aec-024a-4968-928c-cac794ccaa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('svm_model.pkl','wb') as f:\n",
        "    pickle.dump(svm,f)\n"
      ],
      "metadata": {
        "id": "_QG9NKtltVrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "zgwGq6M_uHuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "clf.fit(feat_train, y_train)\n",
        "\n",
        "clf.score(feat_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dIIqltSuJ78",
        "outputId": "b7988e6e-ec64-44c5-e16b-b42306161fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('forest_model.pkl','wb') as f:\n",
        "    pickle.dump(clf,f)"
      ],
      "metadata": {
        "id": "fm7O2PzTuUF_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}