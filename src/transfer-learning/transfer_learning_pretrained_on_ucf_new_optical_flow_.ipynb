{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Note: Check paths before running\n",
        "\n"
      ],
      "metadata": {
        "id": "-kIPzYrYxEis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "FmPADVV4uv2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import ipywidgets\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical, OrderedEnqueuer\n",
        "\n",
        "import ipywidgets\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import wandb\n",
        "# from wandb.keras import WandbCallback, WandbMetricsLogger\n",
        "# Setting seed for reproducibility\n",
        "SEED = 42\n",
        "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "sbvx0xxEuvXi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "tf.test.is_built_with_cuda()\n",
        "print(tf.version.VERSION)\n",
        "import sys\n",
        "sys.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_5nNyGk-KuPb",
        "outputId": "38f51c4c-9d2d-4f51-c4e2-9d1ab9684224"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "2.12.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drive mounting"
      ],
      "metadata": {
        "id": "tgDV5Dsau2jI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kgJrQtAueAi",
        "outputId": "fae5be81-c5f8-4ec2-9b60-8dbcacdd2935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters"
      ],
      "metadata": {
        "id": "VE8Z4kWN29w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# AUTO = tf.data.AUTOTUNE\n",
        "INPUT_SHAPE = (75, 75, 14, 2)\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 1e-5\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = 10\n",
        "\n",
        "# ViViT ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 510\n",
        "NUM_HEADS = 17\n",
        "NUM_LAYERS = 9"
      ],
      "metadata": {
        "id": "VPCXXWYPqr2M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Generator"
      ],
      "metadata": {
        "id": "c1F8slLE1zCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, x_in, y_in, batch_size=BATCH_SIZE, shuffle=True):\n",
        "        # Initialization\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.x = x_in\n",
        "        self.y = y_in\n",
        "        self.datalen = len(y_in)\n",
        "        self.indexes = np.arange(self.datalen)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # get batch indexes from shuffled indexes\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        x_batch = self.x[batch_indexes]\n",
        "        y_batch = self.y[batch_indexes]\n",
        "        return x_batch, y_batch\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch\n",
        "        return self.datalen // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indexes after each epoch\n",
        "        self.indexes = np.arange(self.datalen)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "uImgcpBQ1xLA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross testing the trained model"
      ],
      "metadata": {
        "id": "Pfk8ppEbvICg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Data"
      ],
      "metadata": {
        "id": "HHR0pjbEvDBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH_LAD = '/content/gdrive/MyDrive/LAD2000_Vio_Nor/Vio_nor/'"
      ],
      "metadata": {
        "id": "0_pnWJ4ov-Wo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LAD2000"
      ],
      "metadata": {
        "id": "IAxr0hH_xfuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lad, y_train_lad = np.load(DATA_PATH_LAD + 'Train/X_train_dense_flow.npy',mmap_mode='r'), np.load(DATA_PATH_LAD  + 'Train/y_train_dense_flow.npy', mmap_mode='r')"
      ],
      "metadata": {
        "id": "HyErOfAswqKC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_lad, y_test_lad = np.load(DATA_PATH_LAD + 'Test/X_test_dense_flow.npy',mmap_mode='r'), np.load(DATA_PATH_LAD + 'Test/y_test_dense_flow.npy',mmap_mode='r')"
      ],
      "metadata": {
        "id": "uZkIwLOuxa97"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_lad, y_val_lad = np.load(DATA_PATH_LAD  + 'Val/X_val_dense_flow.npy',mmap_mode='r'), np.load(DATA_PATH_LAD  + 'Val/y_val_dense_flow.npy', mmap_mode='r')"
      ],
      "metadata": {
        "id": "0QJEaT3gxa7Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lad.shape, y_train_lad.shape"
      ],
      "metadata": {
        "id": "LZAYi87Txayk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81eae5a-3262-4fac-9b31-e39818335913"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4778, 75, 75, 14, 2), (4778,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_lad.shape, y_test_lad.shape"
      ],
      "metadata": {
        "id": "wQrlTfstxarv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b026fb1-d1d2-4c1d-f3d4-465b84941d50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1186, 75, 75, 14, 2), (1186,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_lad.shape, y_val_lad.shape"
      ],
      "metadata": {
        "id": "TO8oH0u1xwao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f51ea90-89b3-4b31-b645-eea7f88fcdd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1149, 75, 75, 14, 2), (1149,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Labels"
      ],
      "metadata": {
        "id": "ZuNCTOc61vpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_lad = to_categorical(y_train_lad, 2)\n",
        "y_val_lad = to_categorical(y_val_lad, 2)\n",
        "y_test_lad = to_categorical(y_test_lad, 2)"
      ],
      "metadata": {
        "id": "vtcJPoRZ1xSS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lad = np.moveaxis(X_train_lad, 1, 3)\n",
        "X_val_lad = np.moveaxis(X_val_lad, 1, 3)\n",
        "X_test_lad = np.moveaxis(X_test_lad, 1, 3)"
      ],
      "metadata": {
        "id": "CGf5ESgvNhcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(X_train_lad, y_train_lad)\n",
        "validation_generator = DataGenerator(X_val_lad, y_val_lad)"
      ],
      "metadata": {
        "id": "v8uDkglHOAsw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ViVit Model\n"
      ],
      "metadata": {
        "id": "PPKHIq1G2Y8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TubeletEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches\n"
      ],
      "metadata": {
        "id": "gpL6HxWM2YZ2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, num_tokens, _ = input_shape\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_tokens, output_dim=self.embed_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "\n",
        "    def call(self, encoded_tokens):\n",
        "        # Encode the positions and add it to the encoded tokens\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_tokens = encoded_tokens + encoded_positions\n",
        "        return encoded_tokens"
      ],
      "metadata": {
        "id": "6nzu1V2O2hD8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vivit_classifier(\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    transformer_layers,\n",
        "    num_heads,\n",
        "    embed_dim,\n",
        "    dropout,\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    layer_norm_eps=LAYER_NORM_EPS,\n",
        "    num_classes=2,\n",
        "):\n",
        "    input_shape = INPUT_SHAPE\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = tubelet_embedder(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization and MHSA\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer Normalization and MLP\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
        "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
        "            ]\n",
        "        )(x3)\n",
        "\n",
        "        # Skip connection\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = layers.GlobalAvgPool1D()(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "R_mQLRT_2jlp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the Model"
      ],
      "metadata": {
        "id": "jQxSEmqox0K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = '/content/gdrive/MyDrive/Checkpoints/hptuning-OF-ucf-vivit/checkpoint.tf'"
      ],
      "metadata": {
        "id": "QKHAQQw1vHbg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_vivit_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "                embed_dim=121, patch_size=(\n",
        "                    3,3,3)\n",
        "            ),\n",
        "            positional_encoder=PositionalEncoder(embed_dim=121),\n",
        "        transformer_layers=7,\n",
        "        num_heads=2,\n",
        "        embed_dim=121,\n",
        "        dropout=0.3,\n",
        "    )\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ol2HC0jEuILW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(MODEL_PATH)"
      ],
      "metadata": {
        "id": "NebVaS-w1T08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGS5KV9U0-Xr",
        "outputId": "3a192107-c427-43c2-f33f-a1c9af716fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 75, 75, 14,  0           []                               \n",
            "                                 2)]                                                              \n",
            "                                                                                                  \n",
            " tubelet_embedding (TubeletEmbe  (None, 36, 39)      134823      ['input_1[0][0]']                \n",
            " dding)                                                                                           \n",
            "                                                                                                  \n",
            " positional_encoder (Positional  (None, 36, 39)      1404        ['tubelet_embedding[0][0]']      \n",
            " Encoder)                                                                                         \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 36, 39)      78          ['positional_encoder[0][0]']     \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 36, 39)      5604        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 36, 39)       0           ['multi_head_attention[0][0]',   \n",
            "                                                                  'positional_encoder[0][0]']     \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 36, 39)      78          ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 36, 39)       12363       ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 36, 39)       0           ['sequential[0][0]',             \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 36, 39)      78          ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 36, 39)      5604        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 36, 39)       0           ['multi_head_attention_1[0][0]', \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 36, 39)      78          ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 36, 39)       0           ['sequential_1[0][0]',           \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 36, 39)      78          ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 36, 39)      5604        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 36, 39)       0           ['multi_head_attention_2[0][0]', \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 36, 39)      78          ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 36, 39)       0           ['sequential_2[0][0]',           \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 36, 39)      78          ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 36, 39)      5604        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 36, 39)       0           ['multi_head_attention_3[0][0]', \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 36, 39)      78          ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 36, 39)       0           ['sequential_3[0][0]',           \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 36, 39)      78          ['add_7[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 36, 39)      5604        ['layer_normalization_8[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 36, 39)       0           ['multi_head_attention_4[0][0]', \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 36, 39)      78          ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 36, 39)       0           ['sequential_4[0][0]',           \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 36, 39)      78          ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 36, 39)      5604        ['layer_normalization_10[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 36, 39)       0           ['multi_head_attention_5[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 36, 39)      78          ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_5 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 36, 39)       0           ['sequential_5[0][0]',           \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 36, 39)      78          ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (MultiH  (None, 36, 39)      5604        ['layer_normalization_12[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 36, 39)       0           ['multi_head_attention_6[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 36, 39)      78          ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_6 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 36, 39)       0           ['sequential_6[0][0]',           \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 36, 39)      78          ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (MultiH  (None, 36, 39)      5604        ['layer_normalization_14[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 36, 39)       0           ['multi_head_attention_7[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 36, 39)      78          ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_7 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 36, 39)       0           ['sequential_7[0][0]',           \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 36, 39)      78          ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (MultiH  (None, 36, 39)      5604        ['layer_normalization_16[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 36, 39)       0           ['multi_head_attention_8[0][0]', \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 36, 39)      78          ['add_16[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_8 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 36, 39)       0           ['sequential_8[0][0]',           \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 36, 39)      78          ['add_17[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (MultiH  (None, 36, 39)      5604        ['layer_normalization_18[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 36, 39)       0           ['multi_head_attention_9[0][0]', \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_19 (LayerN  (None, 36, 39)      78          ['add_18[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_9 (Sequential)      (None, 36, 39)       12363       ['layer_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 36, 39)       0           ['sequential_9[0][0]',           \n",
            "                                                                  'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_20 (LayerN  (None, 36, 39)      78          ['add_19[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (Multi  (None, 36, 39)      5604        ['layer_normalization_20[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 36, 39)       0           ['multi_head_attention_10[0][0]',\n",
            "                                                                  'add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_21 (LayerN  (None, 36, 39)      78          ['add_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_10 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 36, 39)       0           ['sequential_10[0][0]',          \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_22 (LayerN  (None, 36, 39)      78          ['add_21[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (Multi  (None, 36, 39)      5604        ['layer_normalization_22[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 36, 39)       0           ['multi_head_attention_11[0][0]',\n",
            "                                                                  'add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_23 (LayerN  (None, 36, 39)      78          ['add_22[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_11 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 36, 39)       0           ['sequential_11[0][0]',          \n",
            "                                                                  'add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_24 (LayerN  (None, 36, 39)      78          ['add_23[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_12 (Multi  (None, 36, 39)      5604        ['layer_normalization_24[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 36, 39)       0           ['multi_head_attention_12[0][0]',\n",
            "                                                                  'add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_25 (LayerN  (None, 36, 39)      78          ['add_24[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_12 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 36, 39)       0           ['sequential_12[0][0]',          \n",
            "                                                                  'add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_26 (LayerN  (None, 36, 39)      78          ['add_25[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_13 (Multi  (None, 36, 39)      5604        ['layer_normalization_26[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 36, 39)       0           ['multi_head_attention_13[0][0]',\n",
            "                                                                  'add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_27 (LayerN  (None, 36, 39)      78          ['add_26[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_13 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 36, 39)       0           ['sequential_13[0][0]',          \n",
            "                                                                  'add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_28 (LayerN  (None, 36, 39)      78          ['add_27[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_14 (Multi  (None, 36, 39)      5604        ['layer_normalization_28[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 36, 39)       0           ['multi_head_attention_14[0][0]',\n",
            "                                                                  'add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_29 (LayerN  (None, 36, 39)      78          ['add_28[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_14 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 36, 39)       0           ['sequential_14[0][0]',          \n",
            "                                                                  'add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_30 (LayerN  (None, 36, 39)      78          ['add_29[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_15 (Multi  (None, 36, 39)      5604        ['layer_normalization_30[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 36, 39)       0           ['multi_head_attention_15[0][0]',\n",
            "                                                                  'add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_31 (LayerN  (None, 36, 39)      78          ['add_30[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_15 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 36, 39)       0           ['sequential_15[0][0]',          \n",
            "                                                                  'add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_32 (LayerN  (None, 36, 39)      78          ['add_31[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (Multi  (None, 36, 39)      5604        ['layer_normalization_32[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 36, 39)       0           ['multi_head_attention_16[0][0]',\n",
            "                                                                  'add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_33 (LayerN  (None, 36, 39)      78          ['add_32[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_16 (Sequential)     (None, 36, 39)       12363       ['layer_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 36, 39)       0           ['sequential_16[0][0]',          \n",
            "                                                                  'add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_34 (LayerN  (None, 36, 39)      78          ['add_33[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 39)          0           ['layer_normalization_34[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 2)            80          ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 444,476\n",
            "Trainable params: 444,476\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/gdrive/MyDrive/Checkpoints/lad-of-pretrained-on-ucf/checkpoint.tf/'\n",
        "model_checkpoint = model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath=checkpoint_filepath,\n",
        "                                save_weights_only=True,\n",
        "                                monitor='val_loss',\n",
        "                                mode='min',\n",
        "                                save_best_only=True\n",
        "                                )"
      ],
      "metadata": {
        "id": "YtRHscscND2J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "checkpoint_filepath = '/content/gdrive/MyDrive/Checkpoints/lad-of-pretrained-on-ucf/checkpoint.tf/'\n",
        "checkpoint = model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath=checkpoint_filepath,\n",
        "                                save_weights_only=True,\n",
        "                                monitor='val_loss',\n",
        "                                mode='min',\n",
        "                                save_best_only=True\n",
        "                                )\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
        "                     monitor=\"val_loss\",\n",
        "                     min_delta=0.025,\n",
        "                     patience=5,\n",
        "                     verbose=0,\n",
        "                     mode=\"min\",\n",
        "                     baseline=None,\n",
        "                     restore_best_weights=False\n",
        "                 )\n",
        "\n",
        "values = np.linspace(0.00001,LEARNING_RATE,14)[::-1].astype(np.float32)\n",
        "boundaries = np.linspace(5, 45,13)[:values.shape[0]-1].astype(np.int32)\n",
        "\n",
        "scheduler = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    list(boundaries), list(values))\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=3, min_lr=0.000001)\n",
        "\n",
        "callbacks = [checkpoint, lr_scheduler, reduce_lr]"
      ],
      "metadata": {
        "id": "K4C-FTdXNWCg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "    # Compile the model with the optimizer, loss function\n",
        "    # and the metrics.\n",
        "    new_model = model\n",
        "    opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    new_model.compile(loss=loss_fn,optimizer=opt,metrics=['accuracy'])\n",
        "    #model.load_weights(checkpoint_filepath)\n",
        "    # Train the model.\n",
        "    history = new_model.fit(training_generator, epochs=20, validation_data=(validation_generator), callbacks=[model_checkpoint, callbacks])\n",
        "\n",
        "    return new_model, history\n",
        "\n",
        "\n",
        "model, history = run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8LljGphMLaw",
        "outputId": "a9eb2210-fd7d-478a-eccc-3b45809d8f5b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 1/20\n",
            "597/597 [==============================] - 136s 110ms/step - loss: 0.7026 - accuracy: 0.5406 - val_loss: 0.6938 - val_accuracy: 0.4991 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 2/20\n",
            "597/597 [==============================] - 64s 107ms/step - loss: 0.6724 - accuracy: 0.5846 - val_loss: 0.6867 - val_accuracy: 0.5376 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 3/20\n",
            "597/597 [==============================] - 61s 101ms/step - loss: 0.6548 - accuracy: 0.6074 - val_loss: 0.7065 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 4/20\n",
            "597/597 [==============================] - 61s 102ms/step - loss: 0.6311 - accuracy: 0.6386 - val_loss: 0.7415 - val_accuracy: 0.5323 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 5/20\n",
            "597/597 [==============================] - 60s 101ms/step - loss: 0.6080 - accuracy: 0.6656 - val_loss: 0.7146 - val_accuracy: 0.5612 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 6/20\n",
            "597/597 [==============================] - 63s 105ms/step - loss: 0.5790 - accuracy: 0.6859 - val_loss: 0.7950 - val_accuracy: 0.5323 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.307692380389199e-05.\n",
            "Epoch 7/20\n",
            "597/597 [==============================] - 61s 103ms/step - loss: 0.5531 - accuracy: 0.7027 - val_loss: 0.8344 - val_accuracy: 0.5297 - lr: 9.3077e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.307692380389199e-05.\n",
            "Epoch 8/20\n",
            "597/597 [==============================] - 61s 103ms/step - loss: 0.5266 - accuracy: 0.7255 - val_loss: 0.8273 - val_accuracy: 0.5664 - lr: 9.3077e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.307692380389199e-05.\n",
            "Epoch 9/20\n",
            "597/597 [==============================] - 60s 101ms/step - loss: 0.5026 - accuracy: 0.7366 - val_loss: 0.8719 - val_accuracy: 0.5594 - lr: 9.3077e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 8.615384285803884e-05.\n",
            "Epoch 10/20\n",
            "597/597 [==============================] - 61s 103ms/step - loss: 0.4722 - accuracy: 0.7588 - val_loss: 0.8998 - val_accuracy: 0.5612 - lr: 8.6154e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.615384285803884e-05.\n",
            "Epoch 11/20\n",
            "597/597 [==============================] - 60s 101ms/step - loss: 0.4519 - accuracy: 0.7753 - val_loss: 0.9858 - val_accuracy: 0.5673 - lr: 8.6154e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.615384285803884e-05.\n",
            "Epoch 12/20\n",
            "597/597 [==============================] - 61s 102ms/step - loss: 0.4315 - accuracy: 0.7850 - val_loss: 1.0082 - val_accuracy: 0.5769 - lr: 8.6154e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 7.923076918814331e-05.\n",
            "Epoch 13/20\n",
            "597/597 [==============================] - 61s 103ms/step - loss: 0.4097 - accuracy: 0.7967 - val_loss: 1.0184 - val_accuracy: 0.5743 - lr: 7.9231e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 7.923076918814331e-05.\n",
            "Epoch 14/20\n",
            "597/597 [==============================] - 61s 102ms/step - loss: 0.3934 - accuracy: 0.8067 - val_loss: 1.1122 - val_accuracy: 0.5559 - lr: 7.9231e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 7.923076918814331e-05.\n",
            "Epoch 15/20\n",
            "597/597 [==============================] - 61s 102ms/step - loss: 0.3832 - accuracy: 0.8139 - val_loss: 1.1386 - val_accuracy: 0.5699 - lr: 7.9231e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 7.923076918814331e-05.\n",
            "Epoch 16/20\n",
            "597/597 [==============================] - 61s 103ms/step - loss: 0.3711 - accuracy: 0.8189 - val_loss: 1.2277 - val_accuracy: 0.5612 - lr: 7.9231e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 7.230769551824778e-05.\n",
            "Epoch 17/20\n",
            "597/597 [==============================] - 60s 100ms/step - loss: 0.3457 - accuracy: 0.8327 - val_loss: 1.1848 - val_accuracy: 0.5734 - lr: 7.2308e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 7.230769551824778e-05.\n",
            "Epoch 18/20\n",
            "597/597 [==============================] - 62s 104ms/step - loss: 0.3333 - accuracy: 0.8375 - val_loss: 1.2761 - val_accuracy: 0.5612 - lr: 7.2308e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 7.230769551824778e-05.\n",
            "Epoch 19/20\n",
            "597/597 [==============================] - 60s 100ms/step - loss: 0.3383 - accuracy: 0.8396 - val_loss: 1.2564 - val_accuracy: 0.5691 - lr: 7.2308e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 6.538461457239464e-05.\n",
            "Epoch 20/20\n",
            "597/597 [==============================] - 62s 104ms/step - loss: 0.3293 - accuracy: 0.8438 - val_loss: 1.3081 - val_accuracy: 0.5708 - lr: 6.5385e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "voSmkewE1ZcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "def eval_model(model,x,y):\n",
        "#     print(model.evaluate(x.reshape(x.shape+(1,)),y_encoded))\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = np.argmax(y_pred,axis = -1)\n",
        "    y_numbers = np.argmax(y,axis=-1)\n",
        "\n",
        "    target_names = ['normal','violence']\n",
        "    labels = target_names\n",
        "    tick_marks = np.arange(len(labels))\n",
        "\n",
        "    print(classification_report(y_numbers, y_pred, target_names=target_names))\n",
        "\n",
        "    z = tf.math.confusion_matrix(y_numbers,y_pred).numpy().astype(np.int64)\n",
        "    z = np.around(z.astype('float') / z.sum(axis=1)[:, np.newaxis], decimals=3)\n",
        "\n",
        "    x = target_names\n",
        "    y = target_names\n",
        "\n",
        "    # change each element of z to type string for annotations\n",
        "    z_text = [[str(y) for y in x] for x in z]\n",
        "\n",
        "    # set up figure\n",
        "    fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
        "\n",
        "    # add title\n",
        "    fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
        "                    #xaxis = dict(title='x'),\n",
        "                    #yaxis = dict(title='x')\n",
        "                    )\n",
        "\n",
        "    # add custom xaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                            x=0.5,\n",
        "                            y=-0.15,\n",
        "                            showarrow=False,\n",
        "                            text=\"Predicted value\",\n",
        "                            xref=\"paper\",\n",
        "                            yref=\"paper\"))\n",
        "\n",
        "    # add custom yaxis title\n",
        "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                            x=-0.35,\n",
        "                            y=0.5,\n",
        "                            showarrow=False,\n",
        "                            text=\"Real value\",\n",
        "                            textangle=-90,\n",
        "                            xref=\"paper\",\n",
        "                            yref=\"paper\"))\n",
        "\n",
        "    # adjust margins to make room for yaxis title\n",
        "    fig.update_layout(margin=dict(t=50, l=200))\n",
        "\n",
        "    # add colorbar\n",
        "    fig['data'][0]['showscale'] = True\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "4SJywpkb7PC0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Note: you may replicate the next cell to test on the train, validation or test dataset"
      ],
      "metadata": {
        "id": "fzPT2hT62LIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing on LAd2000"
      ],
      "metadata": {
        "id": "EKktG9Yj578M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model, X_test_lad, y_test_lad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "ylEBMmz07XO2",
        "outputId": "bd3c54c6-8a60-445c-ba92-2fa2044fa996"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 8s 77ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.55      0.63      0.58       570\n",
            "    violence       0.60      0.52      0.56       616\n",
            "\n",
            "    accuracy                           0.57      1186\n",
            "   macro avg       0.57      0.57      0.57      1186\n",
            "weighted avg       0.57      0.57      0.57      1186\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"cc0e6220-ac5b-4b12-9143-e396ac8c2018\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cc0e6220-ac5b-4b12-9143-e396ac8c2018\")) {                    Plotly.newPlot(                        \"cc0e6220-ac5b-4b12-9143-e396ac8c2018\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"reversescale\":false,\"showscale\":true,\"x\":[\"normal\",\"violence\"],\"y\":[\"normal\",\"violence\"],\"z\":[[0.626,0.374],[0.481,0.519]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"0.626\",\"x\":\"normal\",\"xref\":\"x\",\"y\":\"normal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.374\",\"x\":\"violence\",\"xref\":\"x\",\"y\":\"normal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.481\",\"x\":\"normal\",\"xref\":\"x\",\"y\":\"violence\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"0.519\",\"x\":\"violence\",\"xref\":\"x\",\"y\":\"violence\",\"yref\":\"y\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted value\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Real value\",\"textangle\":-90,\"x\":-0.35,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"<i><b>Confusion matrix</b></i>\"},\"margin\":{\"t\":50,\"l\":200}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cc0e6220-ac5b-4b12-9143-e396ac8c2018');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_lad, y_test_lad)"
      ],
      "metadata": {
        "id": "r3Ed-OUE2Frw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85c8008-8887-4dd7-d443-b81a395e916f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 2s 52ms/step - loss: 1.2314 - accuracy: 0.5708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2314329147338867, 0.5708262920379639]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "\n",
        "def eval_model_f(model,x,y):\n",
        "#     print(model.evaluate(x.reshape(x.shape+(1,)),y_encoded))\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = np.argmax(y_pred,axis = -1)\n",
        "    y_numbers = np.argmax(y,axis=-1)\n",
        "\n",
        "    target_names = [\n",
        "  'normal', 'violence'\n",
        "    ]\n",
        "    tick_marks = np.arange(len(target_names))\n",
        "    print(classification_report(y_numbers, y_pred, target_names=target_names))\n",
        "\n",
        "    conf = cm(y_numbers,y_pred)\n",
        "\n",
        "    sns.heatmap(conf,annot=True)\n",
        "    plt.xticks(tick_marks,target_names,rotation=45)\n",
        "    plt.yticks(tick_marks,target_names,rotation=0)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Qyiito7AWq5M"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model_f(model,X_test_lad,y_test_lad)"
      ],
      "metadata": {
        "id": "d9Y56X8nWqxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "31394aac-1f6e-4e8d-85ec-7662a2365daf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 2s 41ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal       0.55      0.63      0.58       570\n",
            "    violence       0.60      0.52      0.56       616\n",
            "\n",
            "    accuracy                           0.57      1186\n",
            "   macro avg       0.57      0.57      0.57      1186\n",
            "weighted avg       0.57      0.57      0.57      1186\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}